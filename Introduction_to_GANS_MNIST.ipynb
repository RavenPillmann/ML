{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction to GANS - MNIST",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RavenPillmann/ML/blob/master/Introduction_to_GANS_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qmp3xJ80crs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from io import BytesIO\n",
        "import cv2\n",
        "# from PIL import Image\n",
        "import PIL\n",
        "from IPython.display import clear_output, Image, display\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQWGS6sq1SB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, x_test = x_train / 255., x_test / 255."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gooh50GF1j_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "disc_dropout = 0.5\n",
        "\n",
        "def discriminator():\n",
        "  # Using strides rather than max-pooling. Supposedly, this works better\n",
        "  model = tf.keras.models.Sequential()\n",
        "  \n",
        "  model.add(tf.keras.layers.Conv2D(8, kernel_size=3, input_shape=(28, 28, 1), padding='same'))\n",
        "#   model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  model.add(tf.keras.layers.Dropout(rate=disc_dropout))\n",
        "  \n",
        "  model.add(tf.keras.layers.Conv2D(16, kernel_size=3, strides=2, padding='same'))\n",
        "#   model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  model.add(tf.keras.layers.Dropout(rate=disc_dropout))\n",
        "  \n",
        "  model.add(tf.keras.layers.Conv2D(32, kernel_size=3, strides=2, padding='same'))\n",
        "#   model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  model.add(tf.keras.layers.Dropout(rate=disc_dropout))\n",
        "  \n",
        "  model.add(tf.keras.layers.Conv2D(64, kernel_size=3, strides=2, padding='same'))\n",
        "#   model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  model.add(tf.keras.layers.Dropout(rate=disc_dropout))\n",
        "  \n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  \n",
        "  model.add(tf.keras.layers.Dense(100))\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  model.add(tf.keras.layers.Dropout(rate=disc_dropout))\n",
        "  \n",
        "  model.add(tf.keras.layers.Dense(1))\n",
        "  model.add(tf.keras.layers.Activation('sigmoid'))\n",
        "  \n",
        "  return model\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqP00-9J5FqU",
        "colab_type": "code",
        "outputId": "986afe38-882a-4bbc-e924-63f9b801f90f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        }
      },
      "source": [
        "disc_model = discriminator()\n",
        "disc_model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 8)         80        \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 28, 28, 8)         0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 28, 28, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 16)        1168      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 7, 7, 32)          4640      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 4, 4, 64)          18496     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               102500    \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 101       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 126,985\n",
            "Trainable params: 126,985\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5e4_tXX5Kt_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen_dropout = 0.5\n",
        "\n",
        "def generator():\n",
        "  # Noise vector to 28 x 28 x 1\n",
        "    \n",
        "  model = tf.keras.models.Sequential()\n",
        "  \n",
        "  model.add(tf.keras.layers.Dense(7*7*256, input_dim=100))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  \n",
        "  model.add(tf.keras.layers.Reshape((7, 7, 256)))\n",
        "  model.add(tf.keras.layers.Dropout(gen_dropout))\n",
        "\n",
        "  model.add(tf.keras.layers.UpSampling2D())\n",
        "  model.add(tf.keras.layers.Conv2DTranspose(128, 5, padding='same'))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  \n",
        "  model.add(tf.keras.layers.UpSampling2D())\n",
        "  model.add(tf.keras.layers.Conv2DTranspose(64, 5, padding='same'))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  \n",
        "  model.add(tf.keras.layers.Conv2DTranspose(32, 5, padding='same'))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  \n",
        "  model.add(tf.keras.layers.Conv2DTranspose(1, 5, padding='same'))\n",
        "  model.add(tf.keras.layers.Activation('sigmoid'))\n",
        "  \n",
        "  \n",
        "#   model.add(tf.keras.layers.Dense(100, input_shape=(100, 1)))\n",
        "#   model.add(tf.keras.layers.BatchNormalization())\n",
        "#   model.add(tf.keras.layers.Activation('relu'))\n",
        "  \n",
        "#   model.add(tf.keras.layers.Dense(1000))\n",
        "#   model.add(tf.keras.layers.BatchNormalization())\n",
        "#   model.add(tf.keras.layers.Activation('relu'))\n",
        "  \n",
        "#   model.add(tf.keras.layers.Dense(28 * 28 * 1))\n",
        "#   model.add(tf.keras.layers.BatchNormalization())\n",
        "#   model.add(tf.keras.layers.Activation('relu'))\n",
        "  \n",
        "#   model.add(tf.keras.layers.Reshape((28, 28, 1), input_shape=(28 * 28 * 1, 1)))\n",
        "#   model.add(tf.keras.layers.Activation('sigmoid')) # Makes it so that output is between 0 and 1\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGf8KPYOi5pS",
        "colab_type": "code",
        "outputId": "82a5cbba-9ab6-4a5e-b12e-bf20024d1f12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "# noise = np.random.uniform(-1, 1, 100)\n",
        "\n",
        "gen_model = generator()\n",
        "gen_model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 12544)             1266944   \n",
            "_________________________________________________________________\n",
            "batch_normalization_v1 (Batc (None, 12544)             50176     \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d (UpSampling2D) (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose (Conv2DTran (None, 14, 14, 128)       819328    \n",
            "_________________________________________________________________\n",
            "batch_normalization_v1_1 (Ba (None, 14, 14, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 28, 28, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 28, 28, 64)        204864    \n",
            "_________________________________________________________________\n",
            "batch_normalization_v1_2 (Ba (None, 28, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 32)        51232     \n",
            "_________________________________________________________________\n",
            "batch_normalization_v1_3 (Ba (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 1)         801       \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 28, 28, 1)         0         \n",
            "=================================================================\n",
            "Total params: 2,394,241\n",
            "Trainable params: 2,368,705\n",
            "Non-trainable params: 25,536\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQNCbinGjFqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator_optimizer = tf.keras.optimizers.RMSprop(lr=4e-4)\n",
        "# discriminator_optimizer = tf.keras.optimizers.Adagrad(lr=8e-5)\n",
        "\n",
        "discriminator_model = tf.keras.models.Sequential()\n",
        "discriminator_model.add(disc_model)\n",
        "discriminator_model.compile(loss='binary_crossentropy', optimizer=discriminator_optimizer, metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh9EKHqvsUAi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adversarial_optimizer = tf.keras.optimizers.RMSprop(lr=1e-4)\n",
        "# adversarial_optimizer = tf.keras.optimizers.Adagrad(lr=4e-5)\n",
        "\n",
        "adversarial_model = tf.keras.models.Sequential()\n",
        "adversarial_model.add(gen_model)\n",
        "adversarial_model.add(disc_model)\n",
        "adversarial_model.compile(loss='binary_crossentropy', optimizer=adversarial_optimizer, metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrPcc4lin1F-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# /device:GPU:0\n",
        "# sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
        "# tf.keras.backend.set_session(sess)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhWiBSxws5ed",
        "colab_type": "code",
        "outputId": "6ae2dfe9-b6c1-47de-9757-2550d819860d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3488
        }
      },
      "source": [
        "# Training the discriminator and generator\n",
        "number_epochs = 20000\n",
        "batch_size = 64\n",
        "\n",
        "disc_loss = np.array([0., 0.])\n",
        "adv_loss = np.array([0., 0.])\n",
        "\n",
        "for i in range(number_epochs):\n",
        "  real_images = x_train[np.random.randint(0, x_train.shape[0], size=batch_size), :, :]\n",
        "\n",
        "  noise = np.random.uniform(-1., 1., size=[batch_size, 100])\n",
        "  fake_images = gen_model.predict(noise) # Not sure if I should be using gen_model or not\n",
        "  fake_images = fake_images[:, :, :, 0] # Tbh not too sure I should be reshaping like this, but it seems necessary to concatenate\n",
        "    \n",
        "  x = np.concatenate((real_images, fake_images)).reshape(-1, 28, 28, 1)\n",
        "  y = np.ones([2 * batch_size, 1])\n",
        "\n",
        "  y[batch_size:, :] = 0\n",
        "\n",
        "  discriminator_model.trainable=True\n",
        "  disc_loss += np.array(discriminator_model.train_on_batch(x, y))\n",
        "\n",
        "  adv_y = np.ones([batch_size, 1])\n",
        "\n",
        "  noise = np.random.uniform(-1., 1., size=[batch_size, 100])\n",
        "  discriminator_model.trainable=False\n",
        "  adv_loss += np.array(adversarial_model.train_on_batch(noise, adv_y))\n",
        "  \n",
        "  if i % 100 == 0:\n",
        "    print(\"disc_loss:\", (disc_loss / (i+1)), \"adv_loss:\", (adv_loss / (i+1)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "disc_loss: [0.69908321 0.4609375 ] adv_loss: [0.87032056 0.09375   ]\n",
            "disc_loss: [0.11083174 0.96434097] adv_loss: [0.16859366 0.86741955]\n",
            "disc_loss: [0.05587218 0.98208178] adv_loss: [0.08471733 0.93337998]\n",
            "disc_loss: [0.0379618  0.98795681] adv_loss: [0.05657207 0.95551287]\n",
            "disc_loss: [0.02870441 0.99090165] adv_loss: [0.04272464 0.96656796]\n",
            "disc_loss: [0.05276435 0.98779004] adv_loss: [0.04273977 0.97205589]\n",
            "disc_loss: [0.14965755 0.94796433] adv_loss: [0.04562653 0.97389767]\n",
            "disc_loss: [0.19769683 0.92199759] adv_loss: [0.09178723 0.95535396]\n",
            "disc_loss: [0.22182422 0.9103757 ] adv_loss: [0.22516409 0.88617743]\n",
            "disc_loss: [0.26477803 0.88188471] adv_loss: [0.27349356 0.85188332]\n",
            "disc_loss: [0.3065453  0.84947865] adv_loss: [0.31887757 0.81125125]\n",
            "disc_loss: [0.34191342 0.81824052] adv_loss: [0.35221799 0.7837903 ]\n",
            "disc_loss: [0.37144184 0.79060418] adv_loss: [0.37943957 0.76057712]\n",
            "disc_loss: [0.39615088 0.76944418] adv_loss: [0.40209503 0.74275797]\n",
            "disc_loss: [0.41755021 0.74956504] adv_loss: [0.42176583 0.72574277]\n",
            "disc_loss: [0.43602137 0.73326636] adv_loss: [0.43854082 0.71466939]\n",
            "disc_loss: [0.45221844 0.71899887] adv_loss: [0.45326881 0.70278342]\n",
            "disc_loss: [0.46631211 0.70746068] adv_loss: [0.4666088  0.68940146]\n",
            "disc_loss: [0.47878534 0.69749011] adv_loss: [0.47830651 0.67839048]\n",
            "disc_loss: [0.4899066  0.68865071] adv_loss: [0.48912168 0.66591597]\n",
            "disc_loss: [0.49976023 0.68153423] adv_loss: [0.49842734 0.65548476]\n",
            "disc_loss: [0.50881855 0.67481631] adv_loss: [0.50744626 0.64430628]\n",
            "disc_loss: [0.51695745 0.66922351] adv_loss: [0.51595081 0.63334138]\n",
            "disc_loss: [0.52451397 0.66343438] adv_loss: [0.52295314 0.62669763]\n",
            "disc_loss: [0.53137987 0.65837477] adv_loss: [0.53012219 0.61730789]\n",
            "disc_loss: [0.53774136 0.65381035] adv_loss: [0.53637046 0.61009971]\n",
            "disc_loss: [0.54347703 0.64982819] adv_loss: [0.54262569 0.60167964]\n",
            "disc_loss: [0.54882445 0.64601074] adv_loss: [0.54844461 0.59364009]\n",
            "disc_loss: [0.55383995 0.64230967] adv_loss: [0.5540347  0.58585661]\n",
            "disc_loss: [0.55845525 0.63932965] adv_loss: [0.55930022 0.57829735]\n",
            "disc_loss: [0.56282708 0.63626187] adv_loss: [0.56418655 0.57129915]\n",
            "disc_loss: [0.566919   0.63333904] adv_loss: [0.56888222 0.5642182 ]\n",
            "disc_loss: [0.57085424 0.63024982] adv_loss: [0.57320228 0.55784325]\n",
            "disc_loss: [0.57442888 0.62749688] adv_loss: [0.57748498 0.55127708]\n",
            "disc_loss: [0.57775387 0.62534227] adv_loss: [0.58139411 0.54542322]\n",
            "disc_loss: [0.58088488 0.62314785] adv_loss: [0.58537097 0.53926557]\n",
            "disc_loss: [0.58386264 0.62118812] adv_loss: [0.58915228 0.53323296]\n",
            "disc_loss: [0.58663842 0.61943774] adv_loss: [0.59284345 0.52690996]\n",
            "disc_loss: [0.58931659 0.61758213] adv_loss: [0.59633506 0.52127318]\n",
            "disc_loss: [0.59180515 0.61613609] adv_loss: [0.59962915 0.51623782]\n",
            "disc_loss: [0.59418459 0.61458464] adv_loss: [0.60306323 0.51068873]\n",
            "disc_loss: [0.59640833 0.61335269] adv_loss: [0.60630136 0.50562744]\n",
            "disc_loss: [0.59860042 0.6118744 ] adv_loss: [0.60967137 0.50005207]\n",
            "disc_loss: [0.60060918 0.61062108] adv_loss: [0.61257604 0.49555699]\n",
            "disc_loss: [0.60256789 0.60947796] adv_loss: [0.61550589 0.49113483]\n",
            "disc_loss: [0.60438393 0.60847242] adv_loss: [0.61831401 0.48705496]\n",
            "disc_loss: [0.60616414 0.60752758] adv_loss: [0.62088926 0.48336639]\n",
            "disc_loss: [0.60776038 0.60678413] adv_loss: [0.62357049 0.47941262]\n",
            "disc_loss: [0.60917279 0.60634991] adv_loss: [0.6258865  0.47657389]\n",
            "disc_loss: [0.61071182 0.6054552 ] adv_loss: [0.6286661  0.47273197]\n",
            "disc_loss: [0.61205883 0.60492433] adv_loss: [0.63125244 0.46904682]\n",
            "disc_loss: [0.61328519 0.60455058] adv_loss: [0.63387791 0.46540813]\n",
            "disc_loss: [0.61454207 0.60400494] adv_loss: [0.63642963 0.46194241]\n",
            "disc_loss: [0.61571161 0.60358895] adv_loss: [0.63881748 0.45875483]\n",
            "disc_loss: [0.616876   0.60313628] adv_loss: [0.64117371 0.45561007]\n",
            "disc_loss: [0.61797411 0.60276683] adv_loss: [0.64354079 0.45252284]\n",
            "disc_loss: [0.61894843 0.60254865] adv_loss: [0.64555402 0.44991966]\n",
            "disc_loss: [0.61991055 0.60229839] adv_loss: [0.64779455 0.44689528]\n",
            "disc_loss: [0.62075839 0.60221029] adv_loss: [0.64992023 0.44425799]\n",
            "disc_loss: [0.62160986 0.60205103] adv_loss: [0.65201446 0.44178158]\n",
            "disc_loss: [0.62242034 0.6019791 ] adv_loss: [0.65394099 0.43947103]\n",
            "disc_loss: [0.62324439 0.60176738] adv_loss: [0.65605637 0.43675985]\n",
            "disc_loss: [0.62399417 0.60163557] adv_loss: [0.65796627 0.43447881]\n",
            "disc_loss: [0.62474398 0.60140875] adv_loss: [0.65993268 0.43207675]\n",
            "disc_loss: [0.62546317 0.60124273] adv_loss: [0.66174908 0.42987424]\n",
            "disc_loss: [0.6261135  0.60123803] adv_loss: [0.66350408 0.4278909 ]\n",
            "disc_loss: [0.62671453 0.60123703] adv_loss: [0.66531704 0.42573095]\n",
            "disc_loss: [0.62737827 0.60115211] adv_loss: [0.66717082 0.42358417]\n",
            "disc_loss: [0.62792391 0.60123052] adv_loss: [0.6688661  0.42172107]\n",
            "disc_loss: [0.62841775 0.6012874 ] adv_loss: [0.67069094 0.41971272]\n",
            "disc_loss: [0.62893533 0.60125897] adv_loss: [0.67247431 0.41769479]\n",
            "disc_loss: [0.62939432 0.60140077] adv_loss: [0.6744383  0.41546745]\n",
            "disc_loss: [0.6298426  0.60155382] adv_loss: [0.67618712 0.41358188]\n",
            "disc_loss: [0.63026673 0.60166523] adv_loss: [0.67796018 0.4117073 ]\n",
            "disc_loss: [0.63066515 0.60176834] adv_loss: [0.67966623 0.41000372]\n",
            "disc_loss: [0.63110405 0.60180309] adv_loss: [0.68147795 0.40807059]\n",
            "disc_loss: [0.63147132 0.60198288] adv_loss: [0.68323171 0.40621711]\n",
            "disc_loss: [0.63184353 0.6020738 ] adv_loss: [0.68502694 0.40437321]\n",
            "disc_loss: [0.63215623 0.60223048] adv_loss: [0.68665713 0.40281094]\n",
            "disc_loss: [0.63245877 0.60240001] adv_loss: [0.68837481 0.40119724]\n",
            "disc_loss: [0.63277502 0.60255456] adv_loss: [0.6901532  0.39949303]\n",
            "disc_loss: [0.63295565 0.60282006] adv_loss: [0.69168269 0.39807007]\n",
            "disc_loss: [0.63314574 0.60312481] adv_loss: [0.6933313  0.39678469]\n",
            "disc_loss: [0.63343376 0.60324528] adv_loss: [0.69511915 0.39516323]\n",
            "disc_loss: [0.63370367 0.60338427] adv_loss: [0.69673934 0.39371429]\n",
            "disc_loss: [0.63398609 0.60343636] adv_loss: [0.6984002  0.39225716]\n",
            "disc_loss: [0.63422614 0.60358988] adv_loss: [0.70001626 0.39078305]\n",
            "disc_loss: [0.63449769 0.60373   ] adv_loss: [0.70165319 0.38931409]\n",
            "disc_loss: [0.63467105 0.60394415] adv_loss: [0.70332971 0.38788028]\n",
            "disc_loss: [0.63489659 0.60403764] adv_loss: [0.70491379 0.38647343]\n",
            "disc_loss: [0.63511003 0.60426446] adv_loss: [0.7065267  0.38511693]\n",
            "disc_loss: [0.63531331 0.60448714] adv_loss: [0.70814488 0.38379196]\n",
            "disc_loss: [0.63546462 0.60470839] adv_loss: [0.70977646 0.38250088]\n",
            "disc_loss: [0.63560038 0.60490135] adv_loss: [0.71134276 0.38123421]\n",
            "disc_loss: [0.63574648 0.60513094] adv_loss: [0.71283251 0.38012412]\n",
            "disc_loss: [0.63588766 0.60535486] adv_loss: [0.71442091 0.37894531]\n",
            "disc_loss: [0.63605456 0.60554239] adv_loss: [0.71597116 0.37782848]\n",
            "disc_loss: [0.63617435 0.60574458] adv_loss: [0.71741062 0.37682649]\n",
            "disc_loss: [0.63624102 0.60598488] adv_loss: [0.71878123 0.37595335]\n",
            "disc_loss: [0.63637183 0.60618009] adv_loss: [0.7203507  0.37484534]\n",
            "disc_loss: [0.63652406 0.60635108] adv_loss: [0.72202331 0.37363139]\n",
            "disc_loss: [0.63667313 0.60650941] adv_loss: [0.72355192 0.37239506]\n",
            "disc_loss: [0.63676725 0.60670522] adv_loss: [0.72497102 0.37131623]\n",
            "disc_loss: [0.63687089 0.60693592] adv_loss: [0.72651076 0.37019616]\n",
            "disc_loss: [0.63699491 0.60711786] adv_loss: [0.72792455 0.36910513]\n",
            "disc_loss: [0.63708589 0.60730377] adv_loss: [0.72922741 0.36816732]\n",
            "disc_loss: [0.63722852 0.60746554] adv_loss: [0.73062996 0.3671676 ]\n",
            "disc_loss: [0.63734261 0.60764911] adv_loss: [0.73196592 0.36619095]\n",
            "disc_loss: [0.63747723 0.60776635] adv_loss: [0.73320456 0.36524396]\n",
            "disc_loss: [0.63765149 0.60786568] adv_loss: [0.73460223 0.36415237]\n",
            "disc_loss: [0.63780736 0.60793905] adv_loss: [0.73581071 0.36323402]\n",
            "disc_loss: [0.63792866 0.60807374] adv_loss: [0.73698576 0.3622914 ]\n",
            "disc_loss: [0.63805129 0.60822067] adv_loss: [0.73811548 0.36140328]\n",
            "disc_loss: [0.63820068 0.60829656] adv_loss: [0.73919253 0.36061383]\n",
            "disc_loss: [0.63837329 0.60833617] adv_loss: [0.74044707 0.35962991]\n",
            "disc_loss: [0.63853868 0.60838799] adv_loss: [0.7413748  0.35888184]\n",
            "disc_loss: [0.63869391 0.60843825] adv_loss: [0.742116   0.35833791]\n",
            "disc_loss: [0.63890539 0.60838817] adv_loss: [0.74304889 0.35747612]\n",
            "disc_loss: [0.639054   0.60846274] adv_loss: [0.7439435  0.35666866]\n",
            "disc_loss: [0.63922602 0.60849994] adv_loss: [0.74475278 0.35593516]\n",
            "disc_loss: [0.63943148 0.60847468] adv_loss: [0.74556543 0.35516572]\n",
            "disc_loss: [0.63965288 0.60841498] adv_loss: [0.74635473 0.35428245]\n",
            "disc_loss: [0.63985173 0.60837034] adv_loss: [0.74711056 0.35351354]\n",
            "disc_loss: [0.64004418 0.60837534] adv_loss: [0.74786013 0.35277874]\n",
            "disc_loss: [0.64023455 0.60833363] adv_loss: [0.74861101 0.35208098]\n",
            "disc_loss: [0.64039862 0.60834071] adv_loss: [0.74943887 0.35122815]\n",
            "disc_loss: [0.64058853 0.60831606] adv_loss: [0.75007872 0.35054634]\n",
            "disc_loss: [0.64077876 0.60829425] adv_loss: [0.75076471 0.34978668]\n",
            "disc_loss: [0.64095132 0.60821725] adv_loss: [0.75136753 0.34915119]\n",
            "disc_loss: [0.64116841 0.608093  ] adv_loss: [0.75199346 0.34842018]\n",
            "disc_loss: [0.64134711 0.60802234] adv_loss: [0.75262427 0.34758745]\n",
            "disc_loss: [0.64153865 0.60794918] adv_loss: [0.75318459 0.34682586]\n",
            "disc_loss: [0.64172092 0.60787417] adv_loss: [0.75372695 0.34613026]\n",
            "disc_loss: [0.64193345 0.60778384] adv_loss: [0.75426444 0.34546275]\n",
            "disc_loss: [0.64214873 0.60767911] adv_loss: [0.75477555 0.34481102]\n",
            "disc_loss: [0.64236338 0.60758231] adv_loss: [0.75527383 0.34411456]\n",
            "disc_loss: [0.64256438 0.60744557] adv_loss: [0.7556829  0.34349841]\n",
            "disc_loss: [0.64277802 0.60730569] adv_loss: [0.75605456 0.34286161]\n",
            "disc_loss: [0.64298323 0.60717011] adv_loss: [0.75644709 0.34223403]\n",
            "disc_loss: [0.64317706 0.60707582] adv_loss: [0.75684497 0.34161436]\n",
            "disc_loss: [0.64339669 0.60692149] adv_loss: [0.75720927 0.34103033]\n",
            "disc_loss: [0.64361385 0.60679706] adv_loss: [0.75752347 0.3404025 ]\n",
            "disc_loss: [0.64378141 0.60668648] adv_loss: [0.75790683 0.33978131]\n",
            "disc_loss: [0.64395569 0.60659384] adv_loss: [0.75838237 0.33907375]\n",
            "disc_loss: [0.64414238 0.60650139] adv_loss: [0.75869559 0.33857566]\n",
            "disc_loss: [0.64434429 0.60636659] adv_loss: [0.75912794 0.33790665]\n",
            "disc_loss: [0.64456509 0.60617798] adv_loss: [0.75943066 0.33740626]\n",
            "disc_loss: [0.64474629 0.60608919] adv_loss: [0.75966374 0.33699982]\n",
            "disc_loss: [0.64492466 0.60595621] adv_loss: [0.75994566 0.33654082]\n",
            "disc_loss: [0.64512802 0.60579774] adv_loss: [0.76018127 0.33607749]\n",
            "disc_loss: [0.64531941 0.60564973] adv_loss: [0.76041221 0.33565991]\n",
            "disc_loss: [0.64549562 0.60554144] adv_loss: [0.76067162 0.33518889]\n",
            "disc_loss: [0.64571477 0.60540836] adv_loss: [0.76094503 0.33464492]\n",
            "disc_loss: [0.64591187 0.6052612 ] adv_loss: [0.7611999  0.33417648]\n",
            "disc_loss: [0.6461052 0.6051271] adv_loss: [0.76141837 0.33369992]\n",
            "disc_loss: [0.64629542 0.60498516] adv_loss: [0.76165527 0.33326479]\n",
            "disc_loss: [0.6464885  0.60487158] adv_loss: [0.7617976  0.33286027]\n",
            "disc_loss: [0.64669281 0.6046868 ] adv_loss: [0.76199027 0.33235841]\n",
            "disc_loss: [0.64689658 0.60449052] adv_loss: [0.76214526 0.33191926]\n",
            "disc_loss: [0.64708739 0.60430506] adv_loss: [0.76224827 0.33151315]\n",
            "disc_loss: [0.64728993 0.60411654] adv_loss: [0.76237923 0.33116094]\n",
            "disc_loss: [0.64746646 0.60397501] adv_loss: [0.76249044 0.33083252]\n",
            "disc_loss: [0.64767341 0.60378025] adv_loss: [0.76257839 0.33043003]\n",
            "disc_loss: [0.6478752  0.60359554] adv_loss: [0.76275272 0.32994525]\n",
            "disc_loss: [0.64806604 0.60340357] adv_loss: [0.7628938 0.3295607]\n",
            "disc_loss: [0.64825918 0.60320634] adv_loss: [0.76304648 0.32911074]\n",
            "disc_loss: [0.64842916 0.60307079] adv_loss: [0.76319618 0.32867372]\n",
            "disc_loss: [0.64862224 0.60288025] adv_loss: [0.76328561 0.3283458 ]\n",
            "disc_loss: [0.64881349 0.6026799 ] adv_loss: [0.7633911  0.32796876]\n",
            "disc_loss: [0.64898816 0.60253415] adv_loss: [0.76345284 0.32770713]\n",
            "disc_loss: [0.64916638 0.60234554] adv_loss: [0.76352244 0.32736034]\n",
            "disc_loss: [0.64934629 0.60217467] adv_loss: [0.76361953 0.32703223]\n",
            "disc_loss: [0.64952903 0.60201033] adv_loss: [0.76368213 0.3268024 ]\n",
            "disc_loss: [0.64971579 0.6018226 ] adv_loss: [0.7637782  0.32651292]\n",
            "disc_loss: [0.64990404 0.60161862] adv_loss: [0.76385414 0.3262079 ]\n",
            "disc_loss: [0.65007794 0.60143036] adv_loss: [0.76393109 0.32596173]\n",
            "disc_loss: [0.65026954 0.60120474] adv_loss: [0.7640362  0.32559851]\n",
            "disc_loss: [0.6504448  0.60100639] adv_loss: [0.76402542 0.32544242]\n",
            "disc_loss: [0.65063618 0.60076637] adv_loss: [0.7639999  0.32528896]\n",
            "disc_loss: [0.65082213 0.60054824] adv_loss: [0.76402653 0.32507   ]\n",
            "disc_loss: [0.65100678 0.60036291] adv_loss: [0.76404384 0.32483004]\n",
            "disc_loss: [0.65117215 0.60018266] adv_loss: [0.76406966 0.32460396]\n",
            "disc_loss: [0.65134225 0.59999408] adv_loss: [0.76411619 0.32433657]\n",
            "disc_loss: [0.65149355 0.59983616] adv_loss: [0.76413346 0.32413529]\n",
            "disc_loss: [0.65166916 0.59962604] adv_loss: [0.76418593 0.32383855]\n",
            "disc_loss: [0.65183995 0.59942157] adv_loss: [0.76420551 0.32357795]\n",
            "disc_loss: [0.652009   0.59921384] adv_loss: [0.7642325  0.32331847]\n",
            "disc_loss: [0.65217105 0.59904133] adv_loss: [0.76422163 0.32316537]\n",
            "disc_loss: [0.65233326 0.59883118] adv_loss: [0.76424508 0.32288509]\n",
            "disc_loss: [0.65249949 0.59863441] adv_loss: [0.76424852 0.32267721]\n",
            "disc_loss: [0.65266512 0.59843396] adv_loss: [0.76422454 0.32250852]\n",
            "disc_loss: [0.65282823 0.59822948] adv_loss: [0.76424259 0.32234242]\n",
            "disc_loss: [0.65298137 0.59804258] adv_loss: [0.7642205  0.32216258]\n",
            "disc_loss: [0.6531517  0.59786248] adv_loss: [0.76422196 0.32197247]\n",
            "disc_loss: [0.65330818 0.59765967] adv_loss: [0.76424861 0.32170539]\n",
            "disc_loss: [0.65350188 0.59742489] adv_loss: [0.76424936 0.32149553]\n",
            "disc_loss: [0.65367765 0.59718453] adv_loss: [0.76422737 0.32131572]\n",
            "disc_loss: [0.65384209 0.59696129] adv_loss: [0.76419618 0.32114566]\n",
            "disc_loss: [0.65400256 0.59677699] adv_loss: [0.76416629 0.32099468]\n",
            "disc_loss: [0.65416095 0.5966024 ] adv_loss: [0.76417659 0.32081852]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oct2AU6pYPcq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def showarray(a, fmt='jpeg'):\n",
        "  a = np.uint8(np.clip(a, 0, 255))\n",
        "  f = BytesIO()\n",
        "  PIL.Image.fromarray(a).save(f, fmt)\n",
        "  display(Image(data=f.getvalue()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwL7h-UE94qZ",
        "colab_type": "code",
        "outputId": "501f1df1-99f2-4457-e8e8-2e8a2a39f222",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        }
      },
      "source": [
        "random_input = np.random.uniform(-1., 1., size=[1, 100])\n",
        "generated_image = gen_model.predict(random_input)[0, :, :, 0]\n",
        "generated_image = generated_image * 255.\n",
        "\n",
        "# generated_image = cv2.resize(generated_image, (0, 0), fx=2., fy=2.) # Back to full scale\n",
        "\n",
        "%matplotlib inline\n",
        "# im = Image.fromarray(generated_image)\n",
        "# im.show()\n",
        "showarray(generated_image)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0a\nHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEB\nAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1Fh\nByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZ\nWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXG\nx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+u08F/DXVvF8T3xli\n0/R4m2zX9xgIpwTwCRu5wDzxuFW/HPwzTwXotnqa6/balHdymOL7PH8rY6nduNcBXQ+CPC8/jDxb\nY6PEGEcjhp3X/lnED8zfl/Ouj+K/i0614lbQ9KPk6FpWLO1t4G/duU4LYBweRgewFXtdhsvCnwof\nwhrlx5niGS+TUYbWE7/se5ANshzgEru+Xn7wOMc15bXofwp8d6f4GutZmvoZWa6tNkEkKgsrgkgc\n9jn9BXRfD7RfA954sv8AxNbarevaaNCb8afqMKLMzKpYvlWIZVIzwAQcZ6ZbyrXdWl17X9Q1acES\nXlw85Utu27iSFz6AcfhWfRRRRX//2Q==\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXJ8c0da-Hw8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from tensorflow.python.client import device_lib\n",
        "# print(device_lib.list_local_devices())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6yER0rU84Pf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7xX1r2Juhko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}