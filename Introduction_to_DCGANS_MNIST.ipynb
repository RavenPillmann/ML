{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction to DCGANS - MNIST",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RavenPillmann/ML/blob/master/Introduction_to_DCGANS_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qmp3xJ80crs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from io import BytesIO\n",
        "import cv2\n",
        "# from PIL import Image\n",
        "import PIL\n",
        "from IPython.display import clear_output, Image, display\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQWGS6sq1SB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, x_test = x_train / 255., x_test / 255."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZNNGM0wxP5P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba2810d1-909e-4a7c-ac40-d8d609862605"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATQsOooLvudC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d0c99828-1f21-480c-a569-59744f098671"
      },
      "source": [
        "# convert y_train and y_test to one-hot-encoded\n",
        "one_hot_y_train = np.zeros((11, y_train.shape[0]))\n",
        "one_hot_y_test = np.zeros((11, y_test.shape[0]))\n",
        "\n",
        "for i in range(y_train.shape[0]):\n",
        "  val = y_train[i]\n",
        "  one_hot_y_train[val][i] = 1\n",
        "  \n",
        "for i in range(y_test.shape[0]):\n",
        "  val = y_test[i]\n",
        "  one_hot_y_test[val][i] = 1\n",
        "  \n",
        "  \n",
        "print(y_train)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5 0 4 ... 5 6 8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7PI1zKbxWrh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "a1356456-3931-45ae-9067-3d739602bc23"
      },
      "source": [
        "print(one_hot_y_train)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gooh50GF1j_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "disc_dropout = 0.5\n",
        "\n",
        "def discriminator():\n",
        "  # Using strides rather than max-pooling. Supposedly, this works better\n",
        "  model = tf.keras.models.Sequential()\n",
        "  \n",
        "  model.add(tf.keras.layers.Conv2D(8, kernel_size=3, input_shape=(28, 28, 1), padding='same'))\n",
        "#   model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  model.add(tf.keras.layers.Dropout(rate=disc_dropout))\n",
        "  \n",
        "  model.add(tf.keras.layers.Conv2D(16, kernel_size=3, strides=2, padding='same'))\n",
        "#   model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  model.add(tf.keras.layers.Dropout(rate=disc_dropout))\n",
        "  \n",
        "  model.add(tf.keras.layers.Conv2D(32, kernel_size=3, strides=2, padding='same'))\n",
        "#   model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  model.add(tf.keras.layers.Dropout(rate=disc_dropout))\n",
        "  \n",
        "  model.add(tf.keras.layers.Conv2D(64, kernel_size=3, strides=2, padding='same'))\n",
        "#   model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  model.add(tf.keras.layers.Dropout(rate=disc_dropout))\n",
        "  \n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  \n",
        "  model.add(tf.keras.layers.Dense(100))\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  model.add(tf.keras.layers.Dropout(rate=disc_dropout))\n",
        "  \n",
        "  model.add(tf.keras.layers.Dense(11))\n",
        "  model.add(tf.keras.layers.Activation('softmax'))\n",
        "  \n",
        "  return model\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqP00-9J5FqU",
        "colab_type": "code",
        "outputId": "137f32e9-fb14-4cdd-e1d0-145bd31a1ddd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        }
      },
      "source": [
        "disc_model = discriminator()\n",
        "disc_model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 8)         80        \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 28, 28, 8)         0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 28, 28, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 16)        1168      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 7, 7, 32)          4640      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 4, 4, 64)          18496     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               102500    \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 11)                1111      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 11)                0         \n",
            "=================================================================\n",
            "Total params: 127,995\n",
            "Trainable params: 127,995\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5e4_tXX5Kt_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen_dropout = 0.5\n",
        "\n",
        "def generator():\n",
        "  # Noise vector to 28 x 28 x 1\n",
        "    \n",
        "  model = tf.keras.models.Sequential()\n",
        "  \n",
        "  model.add(tf.keras.layers.Dense(7*7*256, input_dim=100))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  \n",
        "  model.add(tf.keras.layers.Reshape((7, 7, 256)))\n",
        "  model.add(tf.keras.layers.Dropout(gen_dropout))\n",
        "\n",
        "  model.add(tf.keras.layers.UpSampling2D())\n",
        "  model.add(tf.keras.layers.Conv2DTranspose(128, 5, padding='same'))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  \n",
        "  model.add(tf.keras.layers.UpSampling2D())\n",
        "  model.add(tf.keras.layers.Conv2DTranspose(64, 5, padding='same'))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  \n",
        "  model.add(tf.keras.layers.Conv2DTranspose(32, 5, padding='same'))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Activation('relu'))\n",
        "  \n",
        "  model.add(tf.keras.layers.Conv2DTranspose(1, 5, padding='same'))\n",
        "  model.add(tf.keras.layers.Activation('sigmoid'))\n",
        "  \n",
        "  \n",
        "#   model.add(tf.keras.layers.Dense(100, input_shape=(100, 1)))\n",
        "#   model.add(tf.keras.layers.BatchNormalization())\n",
        "#   model.add(tf.keras.layers.Activation('relu'))\n",
        "  \n",
        "#   model.add(tf.keras.layers.Dense(1000))\n",
        "#   model.add(tf.keras.layers.BatchNormalization())\n",
        "#   model.add(tf.keras.layers.Activation('relu'))\n",
        "  \n",
        "#   model.add(tf.keras.layers.Dense(28 * 28 * 1))\n",
        "#   model.add(tf.keras.layers.BatchNormalization())\n",
        "#   model.add(tf.keras.layers.Activation('relu'))\n",
        "  \n",
        "#   model.add(tf.keras.layers.Reshape((28, 28, 1), input_shape=(28 * 28 * 1, 1)))\n",
        "#   model.add(tf.keras.layers.Activation('sigmoid')) # Makes it so that output is between 0 and 1\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGf8KPYOi5pS",
        "colab_type": "code",
        "outputId": "68a96db6-2541-4890-c1d1-0ef42d3d6590",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "# noise = np.random.uniform(-1, 1, 100)\n",
        "\n",
        "gen_model = generator()\n",
        "gen_model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 12544)             1266944   \n",
            "_________________________________________________________________\n",
            "batch_normalization_v1 (Batc (None, 12544)             50176     \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d (UpSampling2D) (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose (Conv2DTran (None, 14, 14, 128)       819328    \n",
            "_________________________________________________________________\n",
            "batch_normalization_v1_1 (Ba (None, 14, 14, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 28, 28, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 28, 28, 64)        204864    \n",
            "_________________________________________________________________\n",
            "batch_normalization_v1_2 (Ba (None, 28, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 32)        51232     \n",
            "_________________________________________________________________\n",
            "batch_normalization_v1_3 (Ba (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 1)         801       \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 28, 28, 1)         0         \n",
            "=================================================================\n",
            "Total params: 2,394,241\n",
            "Trainable params: 2,368,705\n",
            "Non-trainable params: 25,536\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQNCbinGjFqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator_optimizer = tf.keras.optimizers.RMSprop(lr=4e-4)\n",
        "# discriminator_optimizer = tf.keras.optimizers.Adagrad(lr=8e-5)\n",
        "\n",
        "discriminator_model = tf.keras.models.Sequential()\n",
        "discriminator_model.add(disc_model)\n",
        "discriminator_model.compile(loss='categorical_crossentropy', optimizer=discriminator_optimizer, metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh9EKHqvsUAi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adversarial_optimizer = tf.keras.optimizers.RMSprop(lr=1e-4)\n",
        "# adversarial_optimizer = tf.keras.optimizers.Adagrad(lr=4e-5)\n",
        "\n",
        "adversarial_model = tf.keras.models.Sequential()\n",
        "adversarial_model.add(gen_model)\n",
        "adversarial_model.add(disc_model)\n",
        "adversarial_model.compile(loss='categorical_crossentropy', optimizer=adversarial_optimizer, metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrPcc4lin1F-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# /device:GPU:0\n",
        "# sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
        "# tf.keras.backend.set_session(sess)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhWiBSxws5ed",
        "colab_type": "code",
        "outputId": "ae687ce7-8ed8-4bd6-8640-8328053649b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3488
        }
      },
      "source": [
        "# Training the discriminator and generator\n",
        "\n",
        "# TODO: Need to modify noise so that it includes the conditions\n",
        "\n",
        "number_epochs = 20000\n",
        "batch_size = 64\n",
        "\n",
        "disc_loss = np.array([0., 0.])\n",
        "adv_loss = np.array([0., 0.])\n",
        "\n",
        "for i in range(number_epochs):\n",
        "  indices = np.random.randint(0, x_train.shape[0], size=batch_size)\n",
        "  real_images = x_train[indices, :, :]\n",
        "  real_y = one_hot_y_train[:, indices]\n",
        "\n",
        "  noise = np.random.uniform(-1., 1., size=[batch_size, 89])\n",
        "  noise = np.concatenate((noise, real_y.T), axis=1)\n",
        "  \n",
        "  fake_images = gen_model.predict(noise)\n",
        "  fake_images = fake_images[:, :, :, 0]\n",
        "    \n",
        "  x = np.concatenate((real_images, fake_images)).reshape(-1, 28, 28, 1)\n",
        "#   y = one_hot_y_train[:, indices]\n",
        "  \n",
        "  fake_y = np.vstack((np.zeros((10, batch_size)), np.ones((1, batch_size))))\n",
        "\n",
        "#   y[batch_size:, :] = 0\n",
        "  y = np.hstack((real_y, fake_y))\n",
        "\n",
        "  discriminator_model.trainable=True\n",
        "  disc_loss += np.array(discriminator_model.train_on_batch(x, y.T))\n",
        "\n",
        "#   adv_y = np.ones([batch_size, 1]) # Needs to be changed... I guess maybe random numbers???\n",
        "  random_numbers = np.random.randint(0, 10, size=batch_size)\n",
        "  \n",
        "  adv_y = np.zeros((11, batch_size))\n",
        "  \n",
        "  for j in range(batch_size):\n",
        "    adv_y[random_numbers[j], j] = 1\n",
        "    \n",
        "  adv_y = adv_y.T\n",
        "  \n",
        "  # TODO: Need to update this now as well\n",
        "\n",
        "  noise = np.random.uniform(-1., 1., size=[batch_size, 89])\n",
        "  noise = np.concatenate((noise, adv_y), axis=1)\n",
        "  \n",
        "  discriminator_model.trainable=False\n",
        "  adv_loss += np.array(adversarial_model.train_on_batch(noise, adv_y))\n",
        "  \n",
        "  if i % 100 == 0:\n",
        "    print(\"disc_loss:\", (disc_loss / (i+1)), \"adv_loss:\", (adv_loss / (i+1)))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "disc_loss: [2.38102484 0.109375  ] adv_loss: [2.41674471 0.078125  ]\n",
            "disc_loss: [1.36326709 0.54873144] adv_loss: [2.613415   0.04857673]\n",
            "disc_loss: [1.18575039 0.60747046] adv_loss: [2.19370873 0.20988806]\n",
            "disc_loss: [1.04521409 0.65391404] adv_loss: [1.72777761 0.37941238]\n",
            "disc_loss: [0.95362687 0.68524002] adv_loss: [1.3912066  0.50448099]\n",
            "disc_loss: [0.98999872 0.67282622] adv_loss: [1.21361512 0.57650324]\n",
            "disc_loss: [1.07344099 0.63060264] adv_loss: [1.21214841 0.55355657]\n",
            "disc_loss: [1.10960192 0.60497281] adv_loss: [1.23526521 0.51228156]\n",
            "disc_loss: [1.12649434 0.58806375] adv_loss: [1.24695013 0.48304853]\n",
            "disc_loss: [1.13146934 0.57815968] adv_loss: [1.25065532 0.46318327]\n",
            "disc_loss: [1.12894485 0.57286464] adv_loss: [1.25918867 0.44204233]\n",
            "disc_loss: [1.12432475 0.56957453] adv_loss: [1.26215458 0.425948  ]\n",
            "disc_loss: [1.1196531  0.56639649] adv_loss: [1.26362975 0.41297617]\n",
            "disc_loss: [1.11512484 0.56265613] adv_loss: [1.2615473  0.40222665]\n",
            "disc_loss: [1.10965975 0.55962817] adv_loss: [1.25629752 0.39455077]\n",
            "disc_loss: [1.10419657 0.55727952] adv_loss: [1.25104273 0.38706487]\n",
            "disc_loss: [1.09848051 0.55496077] adv_loss: [1.24549922 0.38133393]\n",
            "disc_loss: [1.09339682 0.55277227] adv_loss: [1.23896391 0.37677285]\n",
            "disc_loss: [1.08801947 0.55111743] adv_loss: [1.23339107 0.37164249]\n",
            "disc_loss: [1.08189053 0.54995726] adv_loss: [1.22728741 0.36692859]\n",
            "disc_loss: [1.0761893  0.54885448] adv_loss: [1.22068123 0.36371658]\n",
            "disc_loss: [1.07153077 0.54714273] adv_loss: [1.21440435 0.3608252 ]\n",
            "disc_loss: [1.06651105 0.54569301] adv_loss: [1.20739118 0.35823915]\n",
            "disc_loss: [1.06204763 0.54439646] adv_loss: [1.2005857  0.35638038]\n",
            "disc_loss: [1.05760391 0.54304847] adv_loss: [1.19429713 0.35440962]\n",
            "disc_loss: [1.05319875 0.54160523] adv_loss: [1.18750941 0.35272766]\n",
            "disc_loss: [1.04893006 0.54081363] adv_loss: [1.18048371 0.35167964]\n",
            "disc_loss: [1.04496537 0.53951951] adv_loss: [1.17422501 0.3509869 ]\n",
            "disc_loss: [1.04114844 0.53849351] adv_loss: [1.16805689 0.34979695]\n",
            "disc_loss: [1.03735515 0.53757325] adv_loss: [1.162048   0.34903912]\n",
            "disc_loss: [1.03377191 0.53634466] adv_loss: [1.15655456 0.34808189]\n",
            "disc_loss: [1.03021713 0.53565886] adv_loss: [1.15045179 0.34814878]\n",
            "disc_loss: [1.02688229 0.53483042] adv_loss: [1.14513276 0.347533  ]\n",
            "disc_loss: [1.02337801 0.53417052] adv_loss: [1.14026198 0.34636284]\n",
            "disc_loss: [1.01994004 0.53351036] adv_loss: [1.13534104 0.34555554]\n",
            "disc_loss: [1.01686001 0.53277412] adv_loss: [1.13020874 0.34506659]\n",
            "disc_loss: [1.01403093 0.53202235] adv_loss: [1.12537382 0.34452235]\n",
            "disc_loss: [1.01130065 0.53120989] adv_loss: [1.12048976 0.34406664]\n",
            "disc_loss: [1.00865079 0.53045046] adv_loss: [1.11594967 0.34364723]\n",
            "disc_loss: [1.00616731 0.52964184] adv_loss: [1.11103833 0.34360581]\n",
            "disc_loss: [1.00374087 0.52902399] adv_loss: [1.10695037 0.34297676]\n",
            "disc_loss: [1.00124494 0.52840199] adv_loss: [1.10269278 0.3425003 ]\n",
            "disc_loss: [0.99871976 0.52781518] adv_loss: [1.09833977 0.34260444]\n",
            "disc_loss: [0.99637503 0.52713758] adv_loss: [1.09400836 0.34274733]\n",
            "disc_loss: [0.99423061 0.52644818] adv_loss: [1.08990044 0.34271685]\n",
            "disc_loss: [0.99190521 0.52593521] adv_loss: [1.08622106 0.34272592]\n",
            "disc_loss: [0.98950711 0.52550566] adv_loss: [1.08209379 0.34300628]\n",
            "disc_loss: [0.98737214 0.5250246 ] adv_loss: [1.07819686 0.34317167]\n",
            "disc_loss: [0.98510022 0.52457008] adv_loss: [1.07442348 0.34350591]\n",
            "disc_loss: [0.98308263 0.52406078] adv_loss: [1.07101404 0.34328772]\n",
            "disc_loss: [0.98102546 0.52349843] adv_loss: [1.06733656 0.34335008]\n",
            "disc_loss: [0.97930353 0.52293362] adv_loss: [1.06396235 0.34310062]\n",
            "disc_loss: [0.97744738 0.52242808] adv_loss: [1.06082452 0.34268951]\n",
            "disc_loss: [0.97565109 0.5219254 ] adv_loss: [1.05753642 0.34266235]\n",
            "disc_loss: [0.97387718 0.52154404] adv_loss: [1.05413692 0.34287343]\n",
            "disc_loss: [0.97196156 0.52137253] adv_loss: [1.0507293 0.3432927]\n",
            "disc_loss: [0.97028946 0.52107743] adv_loss: [1.04771813 0.34332876]\n",
            "disc_loss: [0.96865883 0.52090094] adv_loss: [1.04461933 0.34357733]\n",
            "disc_loss: [0.96701512 0.52072784] adv_loss: [1.04168028 0.34377694]\n",
            "disc_loss: [0.9655014  0.52042821] adv_loss: [1.03875188 0.34382414]\n",
            "disc_loss: [0.96393347 0.52019846] adv_loss: [1.03582828 0.34385675]\n",
            "disc_loss: [0.96233798 0.51991989] adv_loss: [1.03297    0.34394208]\n",
            "disc_loss: [0.96079059 0.51972338] adv_loss: [1.03009478 0.34427159]\n",
            "disc_loss: [0.95925406 0.51956535] adv_loss: [1.02718485 0.34476918]\n",
            "disc_loss: [0.95785869 0.51941103] adv_loss: [1.02454688 0.34493634]\n",
            "disc_loss: [0.95650691 0.51922781] adv_loss: [1.02179205 0.34543724]\n",
            "disc_loss: [0.95500346 0.51903476] adv_loss: [1.0190693  0.34602238]\n",
            "disc_loss: [0.95376251 0.51883931] adv_loss: [1.01662814 0.346189  ]\n",
            "disc_loss: [0.95245968 0.51869555] adv_loss: [1.01404964 0.34655749]\n",
            "disc_loss: [0.95131625 0.51851634] adv_loss: [1.01163987 0.34675002]\n",
            "disc_loss: [0.95004918 0.51845384] adv_loss: [1.009363   0.34690803]\n",
            "disc_loss: [0.94881527 0.51832708] adv_loss: [1.00695548 0.34727943]\n",
            "disc_loss: [0.94769867 0.51808994] adv_loss: [1.00462765 0.34777071]\n",
            "disc_loss: [0.94657721 0.51796843] adv_loss: [1.0024241  0.34809872]\n",
            "disc_loss: [0.94548213 0.51780165] adv_loss: [1.00032159 0.34825953]\n",
            "disc_loss: [0.9443156  0.51779867] adv_loss: [0.99816224 0.34848062]\n",
            "disc_loss: [0.94326414 0.51780296] adv_loss: [0.99616462 0.34849855]\n",
            "disc_loss: [0.94225273 0.51772396] adv_loss: [0.99429327 0.34852617]\n",
            "disc_loss: [0.94118817 0.51762695] adv_loss: [0.99222217 0.3489136 ]\n",
            "disc_loss: [0.94028501 0.51747999] adv_loss: [0.99022262 0.34920619]\n",
            "disc_loss: [0.93927202 0.51742263] adv_loss: [0.98850376 0.34902083]\n",
            "disc_loss: [0.93820274 0.5173879 ] adv_loss: [0.98663683 0.34928558]\n",
            "disc_loss: [0.9371518  0.51741785] adv_loss: [0.98470043 0.34968297]\n",
            "disc_loss: [0.9362114  0.51741601] adv_loss: [0.98282192 0.34999172]\n",
            "disc_loss: [0.93522989 0.51738818] adv_loss: [0.98122852 0.35003459]\n",
            "disc_loss: [0.93438962 0.51728841] adv_loss: [0.97942865 0.35041282]\n",
            "disc_loss: [0.93351557 0.51719368] adv_loss: [0.97770307 0.35070413]\n",
            "disc_loss: [0.93261748 0.51713165] adv_loss: [0.97607571 0.35087382]\n",
            "disc_loss: [0.93181625 0.51716336] adv_loss: [0.97436927 0.35105563]\n",
            "disc_loss: [0.93093193 0.5171057 ] adv_loss: [0.97284679 0.350956  ]\n",
            "disc_loss: [0.93019122 0.51706668] adv_loss: [0.97126451 0.35111724]\n",
            "disc_loss: [0.92937417 0.51703882] adv_loss: [0.96960305 0.35132643]\n",
            "disc_loss: [0.92857115 0.51696317] adv_loss: [0.96792772 0.35176543]\n",
            "disc_loss: [0.92782988 0.51683623] adv_loss: [0.9663513  0.35193124]\n",
            "disc_loss: [0.9269495  0.51676517] adv_loss: [0.96497628 0.3517794 ]\n",
            "disc_loss: [0.92613942 0.51678524] adv_loss: [0.96359017 0.35177876]\n",
            "disc_loss: [0.92536963 0.51686755] adv_loss: [0.96226627 0.35180743]\n",
            "disc_loss: [0.92467004 0.51682252] adv_loss: [0.96081273 0.35197724]\n",
            "disc_loss: [0.92389994 0.51681509] adv_loss: [0.95948657 0.35196823]\n",
            "disc_loss: [0.92312922 0.51694431] adv_loss: [0.95829444 0.35188523]\n",
            "disc_loss: [0.92252305 0.51699518] adv_loss: [0.95694619 0.35211948]\n",
            "disc_loss: [0.92180177 0.51708912] adv_loss: [0.95560452 0.35235218]\n",
            "disc_loss: [0.92106657 0.51709621] adv_loss: [0.95446582 0.35229389]\n",
            "disc_loss: [0.92043683 0.51724499] adv_loss: [0.95336581 0.3521791 ]\n",
            "disc_loss: [0.91977746 0.51727673] adv_loss: [0.95214318 0.35244658]\n",
            "disc_loss: [0.91917095 0.5173354 ] adv_loss: [0.95097779 0.35257654]\n",
            "disc_loss: [0.91853714 0.51737454] adv_loss: [0.94977979 0.35277332]\n",
            "disc_loss: [0.91800604 0.51730928] adv_loss: [0.94843188 0.35323655]\n",
            "disc_loss: [0.91742445 0.51729296] adv_loss: [0.94718947 0.35349447]\n",
            "disc_loss: [0.91681901 0.51727694] adv_loss: [0.94616013 0.35339504]\n",
            "disc_loss: [0.91619356 0.51735283] adv_loss: [0.94512241 0.35341247]\n",
            "disc_loss: [0.91567163 0.51735134] adv_loss: [0.94404495 0.35353938]\n",
            "disc_loss: [0.91513    0.51727803] adv_loss: [0.94290894 0.35374353]\n",
            "disc_loss: [0.9146186 0.5172876] adv_loss: [0.94194875 0.35375465]\n",
            "disc_loss: [0.91412619 0.51727782] adv_loss: [0.94099609 0.35379572]\n",
            "disc_loss: [0.91365155 0.51731915] adv_loss: [0.93993262 0.35393661]\n",
            "disc_loss: [0.9130667  0.51738199] adv_loss: [0.93896671 0.35401851]\n",
            "disc_loss: [0.91252885 0.51730154] adv_loss: [0.93792355 0.35420183]\n",
            "disc_loss: [0.91208656 0.51731381] adv_loss: [0.93709944 0.35381271]\n",
            "disc_loss: [0.91158258 0.51732063] adv_loss: [0.9363595  0.35348264]\n",
            "disc_loss: [0.91111222 0.51736444] adv_loss: [0.93559335 0.35327915]\n",
            "disc_loss: [0.91063006 0.5173591 ] adv_loss: [0.9346403  0.35340829]\n",
            "disc_loss: [0.91019954 0.51738907] adv_loss: [0.9336808 0.3535891]\n",
            "disc_loss: [0.90965388 0.51748969] adv_loss: [0.93272502 0.35378983]\n",
            "disc_loss: [0.90911682 0.51755655] adv_loss: [0.9318587  0.35388779]\n",
            "disc_loss: [0.90867775 0.51758047] adv_loss: [0.93104897 0.35395293]\n",
            "disc_loss: [0.90840272 0.51757177] adv_loss: [0.93017609 0.35397488]\n",
            "disc_loss: [0.90796105 0.51761119] adv_loss: [0.929414   0.35393744]\n",
            "disc_loss: [0.9075251  0.51766708] adv_loss: [0.92861025 0.35395672]\n",
            "disc_loss: [0.90705921 0.51771362] adv_loss: [0.92785884 0.35376497]\n",
            "disc_loss: [0.90658453 0.51773181] adv_loss: [0.92712261 0.35369996]\n",
            "disc_loss: [0.90617811 0.51779683] adv_loss: [0.92634837 0.35374208]\n",
            "disc_loss: [0.90582156 0.51784311] adv_loss: [0.92564201 0.35362023]\n",
            "disc_loss: [0.90547784 0.51791806] adv_loss: [0.92490794 0.35354837]\n",
            "disc_loss: [0.90513841 0.5179301 ] adv_loss: [0.92406013 0.35375625]\n",
            "disc_loss: [0.90472991 0.51803281] adv_loss: [0.92331827 0.35371107]\n",
            "disc_loss: [0.90432736 0.51812769] adv_loss: [0.92265404 0.35355512]\n",
            "disc_loss: [0.90394878 0.51815732] adv_loss: [0.92193489 0.35353031]\n",
            "disc_loss: [0.90353606 0.51824822] adv_loss: [0.92118463 0.35356134]\n",
            "disc_loss: [0.90316963 0.51832152] adv_loss: [0.92052775 0.35345928]\n",
            "disc_loss: [0.90287881 0.51838317] adv_loss: [0.91985583 0.35353613]\n",
            "disc_loss: [0.90248446 0.51842733] adv_loss: [0.91922568 0.35348889]\n",
            "disc_loss: [0.90209702 0.51848186] adv_loss: [0.91862776 0.35354685]\n",
            "disc_loss: [0.90174825 0.51853236] adv_loss: [0.91802534 0.35351658]\n",
            "disc_loss: [0.90145052 0.51860222] adv_loss: [0.91732792 0.35371459]\n",
            "disc_loss: [0.90114444 0.51862856] adv_loss: [0.91675749 0.35365126]\n",
            "disc_loss: [0.90077431 0.51865989] adv_loss: [0.91617508 0.35355027]\n",
            "disc_loss: [0.90046797 0.51874819] adv_loss: [0.9155973  0.35348254]\n",
            "disc_loss: [0.90014313 0.51880521] adv_loss: [0.91494086 0.35364798]\n",
            "disc_loss: [0.89981234 0.51891022] adv_loss: [0.91435835 0.35366544]\n",
            "disc_loss: [0.89946412 0.51900082] adv_loss: [0.91383188 0.3535858 ]\n",
            "disc_loss: [0.89912676 0.51913522] adv_loss: [0.9133317  0.35351239]\n",
            "disc_loss: [0.89882223 0.51925603] adv_loss: [0.91289082 0.35342247]\n",
            "disc_loss: [0.89853692 0.51929868] adv_loss: [0.91237452 0.35347669]\n",
            "disc_loss: [0.89820504 0.51936563] adv_loss: [0.91172353 0.35369659]\n",
            "disc_loss: [0.89790642 0.51942062] adv_loss: [0.91117825 0.35373121]\n",
            "disc_loss: [0.8975891  0.51951147] adv_loss: [0.91065998 0.35368726]\n",
            "disc_loss: [0.89730755 0.51960614] adv_loss: [0.91022949 0.35356625]\n",
            "disc_loss: [0.89705052 0.51964274] adv_loss: [0.90964302 0.35374047]\n",
            "disc_loss: [0.89674595 0.51968381] adv_loss: [0.90907192 0.35385451]\n",
            "disc_loss: [0.89641548 0.51976195] adv_loss: [0.90850229 0.35400034]\n",
            "disc_loss: [0.89614424 0.51986629] adv_loss: [0.90809196 0.35377752]\n",
            "disc_loss: [0.89580975 0.51995971] adv_loss: [0.90766623 0.35372816]\n",
            "disc_loss: [0.89549149 0.52011667] adv_loss: [0.90726166 0.35364874]\n",
            "disc_loss: [0.89525799 0.52025648] adv_loss: [0.90682415 0.35368651]\n",
            "disc_loss: [0.89499417 0.52038229] adv_loss: [0.90626906 0.35391794]\n",
            "disc_loss: [0.89474521 0.52039222] adv_loss: [0.90574645 0.35408823]\n",
            "disc_loss: [0.89444343 0.5204563 ] adv_loss: [0.90529208 0.35422561]\n",
            "disc_loss: [0.89414555 0.52058425] adv_loss: [0.90483144 0.35428044]\n",
            "disc_loss: [0.89386594 0.52069266] adv_loss: [0.90436542 0.35430873]\n",
            "disc_loss: [0.89364089 0.52077451] adv_loss: [0.90390723 0.35444882]\n",
            "disc_loss: [0.8933354  0.52086409] adv_loss: [0.90347488 0.35448768]\n",
            "disc_loss: [0.89305908 0.52094264] adv_loss: [0.90308633 0.35448611]\n",
            "disc_loss: [0.89281782 0.52098506] adv_loss: [0.90269877 0.35448908]\n",
            "disc_loss: [0.89259105 0.52106964] adv_loss: [0.90236638 0.35433488]\n",
            "disc_loss: [0.89233676 0.52113585] adv_loss: [0.90189161 0.35449224]\n",
            "disc_loss: [0.89207127 0.52120929] adv_loss: [0.90145039 0.3545697 ]\n",
            "disc_loss: [0.89181397 0.52129426] adv_loss: [0.90108177 0.35457831]\n",
            "disc_loss: [0.89157323 0.52138003] adv_loss: [0.90069994 0.35461403]\n",
            "disc_loss: [0.89135875 0.52148754] adv_loss: [0.90033315 0.35458127]\n",
            "disc_loss: [0.89115618 0.52154828] adv_loss: [0.89993062 0.35465044]\n",
            "disc_loss: [0.89090124 0.52165065] adv_loss: [0.89956793 0.35463251]\n",
            "disc_loss: [0.89070665 0.52175061] adv_loss: [0.89917385 0.35465685]\n",
            "disc_loss: [0.89050638 0.52182258] adv_loss: [0.89880109 0.35471252]\n",
            "disc_loss: [0.89029366 0.52190778] adv_loss: [0.89846176 0.3546886 ]\n",
            "disc_loss: [0.89012548 0.52195405] adv_loss: [0.89807815 0.35477896]\n",
            "disc_loss: [0.8899005  0.52203595] adv_loss: [0.89769186 0.35483811]\n",
            "disc_loss: [0.88964152 0.52209691] adv_loss: [0.89734179 0.35481224]\n",
            "disc_loss: [0.88942964 0.52216554] adv_loss: [0.89699254 0.35476504]\n",
            "disc_loss: [0.8892159  0.52223551] adv_loss: [0.8966506  0.35470593]\n",
            "disc_loss: [0.88894578 0.52237876] adv_loss: [0.89640584 0.35467541]\n",
            "disc_loss: [0.88875298 0.52243461] adv_loss: [0.89603227 0.35477936]\n",
            "disc_loss: [0.88853802 0.52255294] adv_loss: [0.89568361 0.35483097]\n",
            "disc_loss: [0.88836704 0.52261177] adv_loss: [0.89536344 0.35477436]\n",
            "disc_loss: [0.88815167 0.52268891] adv_loss: [0.895027   0.35472479]\n",
            "disc_loss: [0.88793993 0.52275364] adv_loss: [0.89473763 0.35466611]\n",
            "disc_loss: [0.88770219 0.52284243] adv_loss: [0.89438115 0.35478021]\n",
            "disc_loss: [0.8874916  0.52290374] adv_loss: [0.89397289 0.3550137 ]\n",
            "disc_loss: [0.88730681 0.52295891] adv_loss: [0.89367985 0.35503336]\n",
            "disc_loss: [0.88706452 0.52303865] adv_loss: [0.89342446 0.35494055]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oct2AU6pYPcq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def showarray(a, fmt='jpeg'):\n",
        "  a = np.uint8(np.clip(a, 0, 255))\n",
        "  f = BytesIO()\n",
        "  PIL.Image.fromarray(a).save(f, fmt)\n",
        "  display(Image(data=f.getvalue()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwL7h-UE94qZ",
        "colab_type": "code",
        "outputId": "f7ebe89e-ed76-41df-c890-1d3191a45152",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        }
      },
      "source": [
        "random_input = np.random.uniform(-1., 1., size=[1, 89])\n",
        "number = np.array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
        "print(number.shape, random_input.shape)\n",
        "random_input = np.hstack((random_input, number))\n",
        "generated_image = gen_model.predict(random_input)[0, :, :, 0]\n",
        "generated_image = generated_image * 255.\n",
        "\n",
        "# generated_image = cv2.resize(generated_image, (0, 0), fx=2., fy=2.) # Back to full scale\n",
        "\n",
        "%matplotlib inline\n",
        "# im = Image.fromarray(generated_image)\n",
        "# im.show()\n",
        "showarray(generated_image)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 11) (1, 89)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0a\nHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEB\nAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1Fh\nByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZ\nWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXG\nx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+u7+Hvwv1P4gJfzwX\nC2VpaphZ5YiyyS9Qg6duSRnGRwc1zniPwvq/hTU2sNYs3t5edjEfJIPVW6EVj1d0bTm1jXLDTEcI\n95cx24YjO0uwXP617P8AE7x3d+CPsXgbwju0220+FDNcKBvkJ5AHHf7zHqxPbnNGLVvEPxT+F2tj\nWbeKRtExdwamUEe4qpLxnHBOz0A6rnsa8Zq9o19NpeuafqFuEM9rcxzRh/ullYEZ9sivefi94J0j\nxF4ut7tfF2gaXeLEkV7b310sbqOocLnJOG6HHQc1wvxG8X6fFo9j4E8KXTPoOnKBcTo3F7NnJJPd\nQ2T6FjkDCqa8yoooor//2Q==\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXJ8c0da-Hw8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from tensorflow.python.client import device_lib\n",
        "# print(device_lib.list_local_devices())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6yER0rU84Pf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7xX1r2Juhko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}